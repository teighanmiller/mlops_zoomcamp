trigger:
- main

pool:
  vmImage: 'ubuntu-latest'

variables:
  TRAIN_YEAR: '2023'
  TRAIN_MONTH: '3'
  ARTIFACT_DIR: '$(Pipeline.Workspace)/train_data'

stages:
- stage: ML_Pipeline
  jobs:

  - job: Read_Train_Data
    displayName: 'Download Training Data'
    steps:
    - script: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
      displayName: "Install python dependencies"
      workingDirectory: 03-orchestration/homework

    - script: |
        mkdir -p data
      displayName: 'Create data directory'
      workingDirectory: 03-orchestration/homework

    - script: |
        python -u scripts/read_data.py --year $(TRAIN_YEAR) --month $(TRAIN_MONTH) --type train --output data/train.parquet
      displayName: 'Run read_data.py for train'
      workingDirectory: 03-orchestration/homework

    - task: PublishBuildArtifacts@1
      inputs:
        pathToPublish: 03-orchestration/homework
        artifactName: train_data

  - job: Read_Val_Data
    displayName: 'Download Validation Data'
    steps:
    - script: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
      displayName: "Install python dependencies"
      workingDirectory: 03-orchestration/homework

    - script: |
        mkdir -p data
      displayName: 'Create data directory'
      workingDirectory: 03-orchestration/homework
      
    - script: |
        python -u scripts/read_data.py --year $(TRAIN_YEAR) --month $(TRAIN_MONTH) --type val --output data/val.parquet
      displayName: 'Run read_data.py for val'
      workingDirectory: 03-orchestration/homework

    - task: PublishBuildArtifacts@1
      inputs:
        pathToPublish: 03-orchestration/homework
        artifactName: val_data

  - job: Preprocess
    dependsOn: [Read_Train_Data, Read_Val_Data]
    displayName: 'Preprocess Features'
    steps:
    - script: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
      displayName: "Install python dependencies"
      workingDirectory: 03-orchestration/homework

    - script: |
        echo "Listing contents of Pipeline.Workspace...."
        find $(Pipeline.Workspace)
      displayName: 'Debug: List downloaded artifacts'


    - task: DownloadBuildArtifacts@0
      inputs:
        artifactName: train_data
        downloadPath: $(Pipeline.Workspace)

    - task: DownloadBuildArtifacts@0
      inputs:
        artifactName: val_data
        downloadPath: $(Pipeline.Workspace)

    - script: |
        python -u scripts/preprocess.py \
          --train_input $(Pipeline.Workspace)/train_data/data/train.parquet \
          --val_input $(Pipeline.Workspace)/val_data/data/val.parquet \
          --output_dir $(Pipeline.Workspace)/preprocessed_data
      displayName: 'Run preprocess.py'
      workingDirectory: 03-orchestration/homework

    - script: |
        echo "DEBUG: List contents of preprocessed_data"
        find $(Pipeline.Workspace)/preprocessed_data
      displayName: 'Debug: Check preprocessed_data files'

    - task: PublishBuildArtifacts@1
      inputs:
        pathToPublish: $(Pipeline.Workspace)/preprocessed_data/
        artifactName: preprocessed_data

  - job: Train
    dependsOn: Preprocess
    displayName: 'Train Model'
    steps:
    - script: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
      displayName: "Install python dependencies"
      workingDirectory: 03-orchestration/homework

    - task: DownloadBuildArtifacts@0
      inputs:
        artifactName: preprocessed_data
        downloadPath: $(Pipeline.Workspace)

    - task: DownloadBuildArtifacts@0
      inputs:
        artifactName: train_data
        downloadPath: $(Pipeline.Workspace)

    - script: |
        echo "DEBUG: Listing contents of train_data artifact"
        find $(Pipeline.Workspace)/train_data
      displayName: 'Debug: Contents of train_data'

    - task: DownloadBuildArtifacts@0
      inputs:
        artifactName: val_data
        downloadPath: $(Pipeline.Workspace)

    - script: |
        echo "DEBUG: Listing contents of $(Pipeline.Workspace)/preprocessed_data"
        find $(Pipeline.Workspace)/preprocessed_data
      displayName: 'Debug: List preprocessed_data contents'

    - script: |
        python -u $(ARTIFACT_DIR)/scripts/train.py \
          --input_dir $(Pipeline.Workspace)/preprocessed_data/preprocessed_data \
          --train_parquet $(ARTIFACT_DIR)/data/train.parquet \
          --val_parquet $(Pipeline.Workspace)/val_data/data/val.parquet \
          --output_dir $(Pipeline.Workspace)/models
      displayName: 'Run train.py'
      workingDirectory: $(Pipeline.Workspace) 

    - task: PublishBuildArtifacts@1
      inputs:
        pathToPublish: models
        artifactName: trained_model